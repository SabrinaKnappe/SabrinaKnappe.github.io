---
layout: post
title: Iteration 2
subtitle: Creating staff forces and testing prototypes.
cover-img: /assets/img/iteration1/notes.png
thumbnail-img: /assets/img/iteration1/notes.png
share-img: /assets/img/iteration1/notes.png
tags: [haptics, coursework, iterations]
---

## The Prototyping Session ##
Last iteration, my team decided that we wanted to start this iteration with a brainstorming session where we would present a lo-fi prototype or sketch of how we feel that the interaction could look like. We decided to do this because of the confusion over what we were trying to achieve might look like. I used cardboard and a knob to mockup the type of movement I thought might be useful for our project. Our project goal is to create an application that can help individuals with dyslexia who want to learn music gain intuition about musical scores. The primary problem that individuals with dyslexia suffer from when trying to read music is an inability to tell which staff line a note is on. I wanted something that would allow you to move horizontally along the time axis and would move you vertically to meet the notes on the staff. My hypothesis is that the up and downward motion would help reinforce the vertical position of the notes. Below is a video of my prototype in action.

<iframe width="560" height="315" src="https://www.youtube.com/embed/XIBzXrAc628" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Here are some sketches that other team members provided. <a href="https://docs.google.com/document/d/1YQwnkiD-qOG7o56Um0f-AZjMjRw0-7mZSucxkRxVg_E/edit?usp=sharing">The notes from the prototyping meeting can be viewed here</a>:

![Hannah's sketch](../assets/img/iteration2/hannahsketch.png){:class="img-responsive"}
![Juliette's sketch](../assets/img/iteration2/juliettesketch-1.jpg){:class="img-responsive"}
![Juliette's sketch](../assets/img/iteration2/juliettesketch-2.jpg){:class="img-responsive"}
![Rubia's sketch](../assets/img/iteration2/rubia-sketch.png){:class="img-responsive"}

We realized that our sketches fell into one of two categories, that had mostly to do with the way the time axis was controlled. In Hannah and Rubia's conception of the program, the time would be constant and pre-programmed, and the haply would simply move you arm up and down. We called this the "rockband" strategy, after the video game where the notes move towards you. In my conception, the user would control the speed at which notes played. Both options have their downsides. The main problem with the "rockband" strategy is that it doesn't allow the user to move and their own pace, or to move back and forth temporally, which we thought might be important when building intuition (you can picture a user moving and back and forth between two notes to hear the difference). The problem with my conception is that it would limit how many notes could be included in one screen and require the user to page between sections of the score somehow. We ultimately ended up going with my strategy because of the potential benefits in solving our problem. This meant we had to come up with a strategy 


**How to evaluate this iteration**
  - Are users able to meaningfully distinguish between note pitches?
  - Are users able to meaningfully distinguish between note durations?
  - Is there an understanding of causality?
  - Do users enjoy the application?

We created a questionnaire together designed to answer these questions, that was based off of a questionnaire created in a previous meeting.
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdF1nb3JWGK2CD8vBRY9muogc-7dK5ZV_FUC1nbfvIpESUTew/viewform?embedded=true" width="640" height="200" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>

**Goals for this iteration**
  - Implement texture on notes
  - Implement forces to move the user between notes
  - Evaluate the results

Based on these goals, we decided to split into two teams like we did for the last iteration.

## Guided Movement ##

![code structure diagram](../assets/img/iteration2/metaphors.png){:class="img-responsive"}

## Implementing Vertical Forces ##

While Juliette focused on implementing gaussians and spring forces, I decided to work on discrete but graded forces on the staff lines. In the last lab (Lab 3) I realized that my understanding of how haply and processing interact in terms of communicating forces was not good, so I started by going through some basic code to better understand what is happening.

![code structure diagram](../assets/img/iteration2/it2_notes.png){:class="img-responsive"}

Below is my code contribution. The variable goUp can be changed in the main .pde file to indicate whether the forces should increase or decrease as you go down the staff lines.

{% highlight processing%}
  private PVector staffForce(PVector posEE, PVector velEE, PShape line) {
    PVector linePos = getPhysicsPosition(line);
    PVector force= new PVector(0, 0);
     //each case of these types of forces will get a different amount of force
    if (abs(posEE.y - linePos.y) < 0.0005) {
      if(goUp){
        if(linePos.y == 0.07125){
          //System.out.println("hello");
          return new PVector(1,2);
        }
        if(linePos.y == 0.07625){
          //System.out.println("how");
          return new PVector(1,1.75);
        }
        if(linePos.y == 0.08125){
          //System.out.println("are");
          return new PVector(1,1.5);
        }
        if(linePos.y == 0.08625){
          //System.out.println("you");
          return new PVector(1,1.25);
        }
        if(linePos.y == 0.09125){
          //System.out.println("today");
          return new PVector(1,1);
        }
        else{
            //System.out.println("didn't work");
        }
      }
      else{
        if(linePos.y == 0.07125){
          //System.out.println("hello");
          return new PVector(1,1);
        }
        if(linePos.y == 0.07625){
          //System.out.println("how");
          return new PVector(1,1.25);
        }
        if(linePos.y == 0.08125){
          //System.out.println("are");
          return new PVector(1,1.5);
        }
        if(linePos.y == 0.08625){
          //System.out.println("you");
          return new PVector(1,1.75);
        }
        if(linePos.y == 0.09125){
          //System.out.println("today");
          return new PVector(1,2);
        }
        else{
            //System.out.println("didn't work");
        }
      }

      //return new PVector(1, 1);
    }
    return force;
  }
{% endhighlight %}

## User Testing ##
My principle contribution to this iteration was creating a user testing protocol and carrying it out with my family as participants. I have video recordings of them giving consent, but I won't include them here for privacy reasons. Below is an outline of the user testing procedure.
{% highlight plaintext %}
Versions to test:
Gaussian only (JR)
Spring only (JR)
Gaussian+spring (JR)
Discrete graded up (SK)
Discrete graded down (SK)

Test all versions on user with no visual or audio feedback (haptic test only). Guide their hand to be above the staff line, instruct them to move their arm up and down. For each version, ask the following:
 - Please describe what you feel.
Test all versions with audio and visual and haptics turned on. Let them freely explore. Ask the following:
 - How does this compare with the previous version of the prototype?
Send them the modified questionnaire.

{% endhighlight %}

Juliette and I had a call where we modified the questionnaire to remove the questions that delt with note duration, since our prototype is geared towards distinguishing note pitch. The modified questionnaire is included before:
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSfQYB43hZJIjVTStAmyP7I-fTb4hOAfTf0l6oybQswc42Iw-g/viewform?embedded=true" width="700" height="200" frameborder="0" marginheight="0" marginwidth="0">Loading…</iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/hUSQNEccS8Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="560" height="315" src="https://www.youtube.com/embed/ogh7KNzVjsI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Results ###


> I couldn’t figure out it was a score and then I had no way of understanding where it started and how to move my hand in order to actually hit the notes in the right direction.


## Future Plans ##

My user testing answered many of our questions in ways that we didn't hope for. As a result, we are going to need to focus our efforts on